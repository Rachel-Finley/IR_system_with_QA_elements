{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "795c6ade-eb04-4d6d-8ff5-e79bb2c4fb1f",
   "metadata": {},
   "source": [
    "# Made in collaboration with Chu Fang, Xiangdi Lin, Rachel Finley, and Dawid Cichoki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3584a6b-742e-4ee5-a96b-f79063229a6f",
   "metadata": {},
   "source": [
    "# Class for NER outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb23d1c-67e7-414a-8e50-7752183aecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''imports and their dependencies'''\n",
    "\n",
    "#!pip install transformers==3\n",
    "#!pip install torch\n",
    "# !pip install tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from tokenizers import Tokenizer\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42953cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertTokenizerFast, BertForTokenClassification, AutoTokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17fb258d-228b-410f-8966-ac5ee893944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_NER():\n",
    "    '''Class to isolate entities from question with NER'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''Initialize models and variables'''\n",
    "        \n",
    "        ### Tokenizer settings\n",
    "        self.tokenizer =  BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "        \n",
    "\n",
    "        ### Model Settings\n",
    "        self.lr = 1e-6\n",
    "        self.batch_size = 32\n",
    "        self.num_epochs = 1\n",
    "        self.max_length = 100\n",
    "        \n",
    "        ### Load/config model &  optimizer\n",
    "        self.device = torch.device(\"cpu\" if not torch.cuda.is_available() else \"cuda\")\n",
    "        self.config = BertConfig(max_position_embeddings = self.max_length, num_labels = 3)\n",
    "        \n",
    "        self.model = BertForTokenClassification.from_pretrained(\"Rachel-Finley/BERT_NER_for_QA_Queries\")\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr = self.lr, weight_decay=0.01)\n",
    "        \n",
    "        ### Attributes initialization\n",
    "        self.tokenized = {}\n",
    "        self.input_ids = {}\n",
    "        self.tokens = {}\n",
    "        self.new_tokens = []\n",
    "        self.new_labels = []\n",
    "        \n",
    "        self.results = {}\n",
    "        self.named_entity_found = []\n",
    "        self.results_final = []\n",
    "        \n",
    "        self.pattern = r'\\[\\w+\\]'\n",
    "    \n",
    "    def run_model(self, question):\n",
    "        '''Tokenizes question, predicts entities, saves results to class attribute'''\n",
    "        \n",
    "        ### tokenize\n",
    "        split_questions = question.split()\n",
    "        self.tokenized = self.tokenizer(split_questions, is_split_into_words=True, return_tensors='pt')\n",
    "        \n",
    "        ### run model\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**self.tokenized).logits\n",
    "        \n",
    "        ### save logits, decode predictions, and clean the result\n",
    "        self.results = logits.argmax(-1).tolist()[0]\n",
    "        encoded_input_ids = self.tokenized[\"input_ids\"].tolist()[0]\n",
    "        self.named_entity_found = [encoded_input_ids[i] for i,x in enumerate(self.results) if x == 1 or x == 2]\n",
    "        self.results_final = self.tokenizer.decode(self.named_entity_found)\n",
    "        self.results_final = re.sub(self.pattern, '', self.results_final)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a583e69-8f63-4d56-ab10-2ccb8915046c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question = \"when was the treaty of versiallies signed in world war two?\"\n",
    "\n",
    "ner_model = BERT_NER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96c50cc-3561-4f55-b832-01f6e9ff512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model.run_model(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6c2ae70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when was the of versiallies signed in war two '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model.results_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfb1cb3-a226-453e-b715-db2b56e94d51",
   "metadata": {},
   "source": [
    "# Class for Querying Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "914f0de7-1b1d-44dc-a6ac-6742a1026699",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''imports and their dependencies'''\n",
    "\n",
    "# !pip install wikipedia \n",
    "\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "900e3463-e6a2-4deb-b4c8-055986ff5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wiki():\n",
    "    '''class to query wikipedia and save the contents'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''initializing dictionaries'''\n",
    "        self.wiki_results = {}\n",
    "        self.wiki_summaries = {}\n",
    "    \n",
    "    def query_wiki(self, output: str,  num_results: int):\n",
    "        '''Parameters: NER output, n articles to retrieve'''\n",
    "    \n",
    "        # query wikipedia using the output of the NER model\n",
    "        # get top n wiki results in the form of article names\n",
    "        for idx, result in enumerate(wikipedia.search(output, num_results, suggestion = True)):\n",
    "            self.wiki_results[idx] = result\n",
    "        # use them to query wikipedia for content of summaries\n",
    "        for idx, article in enumerate(self.wiki_results[0]):\n",
    "            self.wiki_summaries[idx] = wikipedia.page(article).summary\n",
    "        list(self.wiki_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "915e98d7-865a-4df5-a998-97d6b0bf20d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Treaty of Versailles', 'Article 231 of the Treaty of Versailles', 'World War I reparations', 'U.S.–German Peace Treaty (1921)']\n",
      "{0: 'The Treaty of Versailles was a peace treaty signed on 28 June 1919. As the most important treaty of World War I, it ended the state of war between Germany and most of the Allied Powers. It was signed in the Palace of Versailles, exactly five years after the assassination of Archduke Franz Ferdinand, which led to the war. The other Central Powers on the German side signed separate treaties.  The United States never ratified the Versailles treaty and made a separate peace treaty with Germany.  Although the armistice of 11 November 1918 ended the actual fighting, it took six months of Allied negotiations at the Paris Peace Conference to conclude the peace treaty. Germany was not allowed to participate in the negotiations—it was forced to sign the final result.  \\nThe most critical and controversial provision in the treaty was: \"The Allied and Associated Governments affirm and Germany accepts the responsibility of Germany and her allies for causing all the loss and damage to which the Allied and Associated Governments and their nationals have been subjected as a consequence of the war imposed upon them by the aggression of Germany and her allies.\" The other members of the Central Powers signed treaties containing similar articles. This article, Article 231, became known as the War Guilt clause. The treaty required Germany to disarm, make ample territorial concessions, and pay reparations to certain countries that had formed the Entente powers. In 1921 the total cost of these reparations was assessed at 132 billion gold marks (then $31.4 billion or £6.6 billion, roughly equivalent to US$442 billion or UK£284 billion in 2023).  Because of the way the deal was structured, the Allied Powers intended Germany would only ever pay a value of 50 billion marks.\\nProminent economists such as John Maynard Keynes declared the treaty too harsh—a \"Carthaginian peace\"—and said the reparations were excessive and counter-productive. On the other hand, prominent Allied figures such as French Marshal Ferdinand Foch, criticized the treaty for treating Germany too leniently. This is still the subject of ongoing debate by historians and economists.The result of these competing and sometimes conflicting goals among the victors was a compromise that left no one satisfied. In particular, Germany was neither pacified nor conciliated, nor was it permanently weakened. The problems that arose from the treaty would lead to the Locarno Treaties, which improved relations between Germany and the other European powers. The reparation system was reorganized resulting in the Dawes Plan, the Young Plan, and the indefinite postponement of reparations at the Lausanne Conference of 1932. The treaty\\'s terms against Germany resulted in economic collapse and bitter resentment which powered the rise of the Nazi Party, and eventually the outbreak of a second World War.\\nAlthough it is often referred to as the \"Versailles Conference\", only the actual signing of the treaty took place at the historic palace. Most of the negotiations were in Paris, with the \"Big Four\" meetings taking place generally at the French Ministry of Foreign Affairs on the Quai d\\'Orsay.', 1: 'Article 231, often known as the War Guilt Clause, was the opening article of the reparations section of the Treaty of Versailles, which ended the First World War between the German Empire and the Allied and Associated Powers. The article did not use the word \"guilt\" but it served as a legal basis to compel Germany to pay reparations for the war.\\nArticle 231 was one of the most controversial points of the treaty. It specified: \\n\\n\"The Allied and Associated Governments affirm and Germany accepts the responsibility of Germany and her allies for causing all the loss and damage to which the Allied and Associated Governments and their nationals have been subjected as a consequence of the war imposed upon them by the aggression of Germany and her allies.\"Germans viewed this clause as a national humiliation, forcing Germany to accept full responsibility for causing the war. German politicians were vocal in their opposition to the article in an attempt to generate international sympathy, while German historians worked to undermine the article with the objective of subverting the entire treaty. The Allied leaders were surprised at the German reaction; they saw the article only as a necessary legal basis to extract compensation from Germany. The article, with the signatory\\'s name changed, was also included in the treaties signed by Germany\\'s allies who did not view the clause with the same disdain as the Germans did. American diplomat John Foster Dulles—one of the two authors of the article—later regretted the wording used, believing it further aggravated the German people.\\nThe historical consensus is that responsibility or guilt for the war was not attached to the article. Rather, the clause was a prerequisite to allow a legal basis to be laid out for the reparation payments that were to be made. Historians have also highlighted the unintended damage created by the clause, which caused anger and resentment amongst the German population.', 2: 'Following the ratification of article 231 of the Treaty of Versailles at the conclusion of World War I, the Central Powers were made to give war reparations to the Allied Powers. Each of the defeated powers was required to make payments in either cash or kind. Because of the financial situation in Austria, Hungary, and Turkey after the war, few to no reparations were paid and the requirements for reparations were cancelled. Bulgaria, having paid only a fraction of what was required, saw its reparation figure reduced and then cancelled. Historians have recognized the German requirement to pay reparations as the \"chief battleground of the post-war era\" and \"the focus of the power struggle between France and Germany over whether the Versailles Treaty was to be enforced or revised.\"The Treaty of Versailles (signed in 1919) and the 1921 London Schedule of Payments required Germany to pay 132 billion gold marks (US$33 billion [all values are contemporary, unless otherwise stated]) in reparations to cover civilian damage caused during the war. This figure was divided into three categories of bonds: A, B, and C. Of these, Germany was required to pay towards \\'A\\' and \\'B\\' bonds totaling 50 billion marks (US$12.5 billion) unconditionally. The payment of the remaining \\'C\\' bonds was interest free and contingent on the Weimar Republic\\'s ability to pay, as was to be assessed by an Allied committee.\\nDue to the lack of reparation payments by Germany, France occupied the Ruhr in 1923 to enforce payments, causing an international crisis that resulted in the implementation of the Dawes Plan in 1924. This plan outlined a new payment method and raised international loans to help Germany to meet its reparation commitments. Despite this, by 1928 Germany called for a new payment plan, resulting in the Young Plan that established the German reparation requirements at 112 billion marks (US$26.3 billion) and created a schedule of payments that would see Germany complete payments by 1988. With the collapse of the German economy in 1931, reparations were suspended for a year and in 1932 during the Lausanne Conference they were cancelled altogether. Between 1919 and 1932, Germany paid less than 21 billion marks in reparations.\\nThe German people saw reparations as a national humiliation; the German Government worked to undermine the validity of the Treaty of Versailles and the requirement to pay. British economist John Maynard Keynes called the treaty a Carthaginian peace that would economically destroy Germany. His arguments had a profound effect on historians, politicians, and the public at large. Despite Keynes\\' arguments and those by later historians supporting or reinforcing Keynes\\' views, the consensus of contemporary historians is that reparations were not as intolerable as the Germans or Keynes had suggested and were within Germany\\'s capacity to pay had there been the political will to do so. Following the Second World War, West Germany took up payments. The 1953 London Agreement on German External Debts resulted in an agreement to pay 50 percent of the remaining balance. The final payment was made on 3 October 2010, settling German loan debts in regard to reparations.', 3: 'The U.S.–German Peace Treaty was a peace treaty between the U.S. and the German governments. It was signed in Berlin on August 25, 1921 in the aftermath of World War I. The main reason for the conclusion of that treaty was the fact that the U.S. Senate did not consent to ratification of the multilateral peace treaty signed in Versailles, thus leading to a separate peace treaty. Ratifications were exchanged in Berlin on November 11, 1921, and the treaty became effective on the same day. The treaty was registered in League of Nations Treaty Series on August 12, 1922.'}\n"
     ]
    }
   ],
   "source": [
    "wiki = Wiki()\n",
    "wiki.query_wiki(\"the treaty of versailles world war two\", 4)\n",
    "print(wiki.wiki_results[0])\n",
    "print(wiki.wiki_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48019250-2189-4e58-a870-f2dac6208620",
   "metadata": {},
   "source": [
    "# Class for QA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdc6a7f0-d38b-4ec4-bb52-35c4eb73286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''imports and their dependencies'''\n",
    "\n",
    "# !pip install torch\n",
    "# !pip install transformers==3\n",
    "# !pip install tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a2a9f3a-04b0-4fe9-970a-df384ca48336",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_QA():\n",
    "    '''class for running QA model on the summaries'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''initialize models, and variables'''\n",
    "        \n",
    "        # models\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"csarron/bert-base-uncased-squad-v1\")\n",
    "        self.model = AutoModelForQuestionAnswering.from_pretrained(\"csarron/bert-base-uncased-squad-v1\")\n",
    "        \n",
    "        # encoded text data, model inputs, embeddings, text\n",
    "        self.encoding = {}\n",
    "        self.inputs = {}\n",
    "        self.sentence_embedding = {}\n",
    "        self.tokens = {}\n",
    "        \n",
    "        # index of QA model's answer\n",
    "        self.start_scores = {}\n",
    "        self.end_scores = {}\n",
    "        self.start_index = {}\n",
    "        self.end_index = {}\n",
    "        self.outputs = {}\n",
    "        \n",
    "        # predicted answer's text\n",
    "        self.init_answer = \"\"\n",
    "        self.cleaned_answer = \"\"\n",
    "        \n",
    "        # preprocessing variables to save split text data\n",
    "        self.split_total = []\n",
    "        self.split_partial = []\n",
    "        \n",
    "    def get_split_tokens(self, wiki_summaries):\n",
    "        '''splits text from wiki summaries to be right size for BERT model'''\n",
    "\n",
    "        if len(wiki_summaries.split())//150 >0:\n",
    "            n = len(wiki_summaries.split())//150\n",
    "        else: \n",
    "            n = 1\n",
    "        for w in range(n):\n",
    "            if w == 0:\n",
    "                self.split_partial = wiki_summaries.split()[:200]\n",
    "                self.split_total.append(\" \".join(self.split_partial))\n",
    "            else:\n",
    "                self.split_partial = wiki_summaries.split()[w*150:w*150 + 200]\n",
    "                self.split_total.append(\" \".join(self.split_partial))\n",
    "        \n",
    "    def pre_process(self, question, split_wiki_summaries):\n",
    "        '''tokenizes and encodes question/context for BERT model'''\n",
    "        \n",
    "        self.encoding = self.tokenizer.encode_plus(text = question, text_pair = self.split_total[0])\n",
    "        # token embeddings\n",
    "        self.inputs = self.encoding['input_ids']\n",
    "        # segment embeddings\n",
    "        self.sentence_embedding = self.encoding['token_type_ids']\n",
    "        # input tokens\n",
    "        self.tokens = self.tokenizer.convert_ids_to_tokens(self.inputs)\n",
    "        \n",
    "\n",
    "    def predict(self):\n",
    "        '''uses BERT model to predict the span of text with answer'''\n",
    "        \n",
    "        ################# NEED SOME KIND OF PADDING HERE FOR MULTIPLE CONTEXTS ###################################\n",
    "                        #### all vectors need to be the same size\n",
    "                        #### pad shorter contexts with the token id 0\n",
    "                \n",
    "        # run QA model to index predicted answer\n",
    "        for batch in tqdm(self.tokens):\n",
    "            self.outputs = self.model(input_ids=torch.tensor([self.inputs]), token_type_ids=torch.tensor([self.sentence_embedding]))\n",
    "            self.start_index = torch.argmax(self.outputs.start_logits)\n",
    "            self.end_index = torch.argmax(self.outputs.end_logits)\n",
    "\n",
    "            # return predicted answer as string\n",
    "            self.init_answer = ' '.join(self.tokens[self.start_index : self.end_index + 1])\n",
    "            for word in self.init_answer.split():\n",
    "                if word[0:2] == '##':\n",
    "                    self.cleaned_answer += word[2:]\n",
    "                else:\n",
    "                    self.cleaned_answer += ' ' + word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5862dd97-5f30-4716-8787-538d37b944f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236/236 [02:50<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "qa = BERT_QA()\n",
    "question = \"when was the treaty of versiallies signed in world war two?\"\n",
    "qa.get_split_tokens(wiki.wiki_summaries[0])\n",
    "qa.pre_process(question, qa.split_total[0])\n",
    "qa.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3ffef61-b0de-4096-96b2-c32e46de84d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 june 1919\n"
     ]
    }
   ],
   "source": [
    "print(qa.init_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac2aa2c-21ec-4b40-8ea3-1b75f7538b44",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Main Function/ Testing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af2bdf41-7fbd-4059-b62b-935ca090bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ner = BERT_NER()\n",
    "    wiki = Wiki()\n",
    "    qa = BERT_QA()\n",
    "    \n",
    "    question = input(\"Search Bar:\")\n",
    "    \n",
    "    ner.run_model(question)\n",
    "    wiki.query_wiki(ner.results_final, 2)\n",
    "    qa.get_split_tokens(wiki.wiki_summaries[0])\n",
    "    qa.pre_process(question, qa.split_total[0])\n",
    "    qa.predict()\n",
    "    \n",
    "    print(qa.init_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03ab127f-f8d3-403a-a8d0-c4fce31db17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Search Bar: what was the largest battle in the Napoleonic Wars?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [04:36<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the french invasion of russia ( 1812 ) . they were the most widespread and costly wars in european history before world war i\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
